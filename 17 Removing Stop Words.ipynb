{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50a97490",
      "metadata": {
        "id": "50a97490"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 28px; color: magenta\"> Python for NLP: Removing Stop Words from Strings</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "HmZ_uiWn7gZt",
      "metadata": {
        "id": "HmZ_uiWn7gZt"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "232621eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "232621eb",
        "outputId": "ca932980-5c42-4fc3-cd16-b6275297a558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n Stop words are those words in natural language that have a very little meaning, \\n  such as \"is\", \"an\", \"the\", etc.\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        " Stop words are those words in natural language that have a very little meaning, \n",
        "  such as \"is\", \"an\", \"the\", etc.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "333c8955",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "333c8955",
        "outputId": "1b95d96c-2335-4063-db0c-4b49a0a918d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The dataset contains comments from Wikipedia's talk page edits.\\nThere are six output labels for each comment: toxic, severe_toxic, obscene, threat, insult and identity_hate.\\nA comment can belong to all of these categories or a subset of these categories,\\n    which makes it a multi-label classification problem\\nThe dataset for this article can be downloaded from this Kaggle link.\\nWe will only use the train.csv file that contains 160,000 records\\n\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''Stop words are often removed from the text before training deep learning and machine learning models \n",
        "since stop words occur in abundance\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df2810b",
      "metadata": {
        "id": "4df2810b"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Using Python's NLTK Library</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8cc7ed5c",
      "metadata": {
        "id": "8cc7ed5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\38067\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'fond', 'tennis', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d9f9f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''You can see that the words to, he, is, not, and too have been removed from the sentence.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c7323a3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nick likes play football , fond tennis .\n"
          ]
        }
      ],
      "source": [
        "filtered_sentence = (\" \").join(tokens_without_sw)\n",
        "print(filtered_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e58940f",
      "metadata": {
        "id": "4e58940f"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Adding or Removing Stop Words in NLTK's Default Stop Word List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "731e5c63",
      "metadata": {
        "id": "731e5c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ],
      "source": [
        "''' let's see the list of all the English stop words supported by NLTK:'''\n",
        "print(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f6fce17",
      "metadata": {
        "id": "4f6fce17"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Adding Stop Words to Default NLTK Stop Word List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8e5a53db",
      "metadata": {
        "id": "8e5a53db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'football', ',', 'however', 'fond', 'tennis', '.']\n"
          ]
        }
      ],
      "source": [
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.append('play')\n",
        "\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2455a0ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2455a0ce",
        "outputId": "fb394db3-4025-46f3-8171-172f902a6bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You should be fired, you're a moronic wimp who is too lazy to do research. It makes me sick that people like you exist in this world.\n"
          ]
        }
      ],
      "source": [
        "'''The output shows that the word play has been removed.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b4624d7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4624d7a",
        "outputId": "2f53db53-3871-4484-d949-7e692d7c282a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'football', ',', 'however', 'fond', 'tennis', '.']\n"
          ]
        }
      ],
      "source": [
        "'''You can also add a list of words to the stopwords.words list using the append method, as shown below:'''\n",
        "sw_list = ['likes','play']\n",
        "all_stopwords.extend(sw_list)\n",
        "\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f8df349f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "f8df349f",
        "outputId": "37e843d0-5217-4fe1-a233-b638df56caee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The script above adds two words likes and play to the stopwords.word list. \\nIn the output, you will not see these two words as shown below:'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''The script above adds two words likes and play to the stopwords.word list. \n",
        "In the output, you will not see these two words as shown below:'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ed155ba",
      "metadata": {
        "id": "0ed155ba"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Removing Stop Words from Default NLTK Stop Word List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6e1bc6bd",
      "metadata": {
        "id": "6e1bc6bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'however', 'not', 'fond', 'tennis', '.']\n"
          ]
        }
      ],
      "source": [
        "'''The following script removes the stop word not from the default list of stop words in NLTK:'''\n",
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.remove('not')\n",
        "\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efb59195",
      "metadata": {
        "id": "efb59195"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Using Python's Gensim Library</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e30ce45d",
      "metadata": {
        "id": "e30ce45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nick likes play football, fond tennis.\n"
          ]
        }
      ],
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "filtered_sentence = remove_stopwords(text)\n",
        "\n",
        "print(filtered_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef08d4a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''For example, the Gensim library considered the word however to be a stop word while NLTK did not, \n",
        "and hence didn't remove it.'''\n",
        "'''It is important to mention that the output \n",
        "after removing stop words using the NLTK and Gensim libraries is different'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec16f010",
      "metadata": {
        "id": "ec16f010"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Adding and Removing Stop Words in Default Gensim Stop Words List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0248af9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0248af9a",
        "outputId": "087cbd02-78fa-4c01-fcf0-40b9cce15213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frozenset({'except', 'together', 'above', 'regarding', 'name', 'thick', 'becoming', 'fifty', 'seems', 'between', 'himself', 'next', 'unless', 'doesn', 'other', 'herself', 'did', 'elsewhere', 'through', 'nothing', 'neither', 'because', 'whereafter', 'before', 'thereafter', 'least', 'whatever', 'side', 'should', 'behind', 'themselves', 'then', 'couldnt', 'un', 'else', 'seeming', 'nor', 're', 'describe', 'move', 'though', 'interest', 'keep', 'thereby', 'somehow', 'below', 'any', 'beyond', 'always', 'km', 'could', 'further', 'yourselves', 'eg', 'done', 'fire', 'whenever', 'all', 'very', 'that', 'along', 'anyway', 'otherwise', 'really', 'serious', 'almost', 'will', 'by', 'three', 'yours', 'him', 'so', 'why', 'seemed', 'upon', 'fifteen', 'however', 'anywhere', 'beside', 'meanwhile', 'it', 'during', 'therefore', 'without', 'her', 'sixty', 'i', 'whole', 'cannot', 'show', 'everything', 'afterwards', 'eleven', 'less', 'still', 'full', 'such', 'on', 'onto', 'were', 'various', 'thin', 'whether', 'a', 'only', 'his', 'been', 'their', 'none', 'via', 'must', 'among', 'whereupon', 'whom', 'cant', 'whoever', 'another', 'bill', 'if', 'was', 'well', 'latter', 'cry', 'besides', 'am', 'is', 'even', 'whereby', 'have', 'they', 'although', 'somewhere', 'about', 'call', 'across', 'much', 'six', 'being', 'part', 'whence', 'those', 'some', 'noone', 'no', 'bottom', 'everyone', 'thru', 'once', 'out', 'hereafter', 'seem', 'too', 'either', 'wherein', 'few', 'most', 'he', 'become', 'hasnt', 'nobody', 'thus', 'using', 'may', 'give', 'several', 'does', 'hundred', 'be', 'now', 'both', 'found', 'see', 'ours', 'formerly', 'there', 'used', 'co', 'beforehand', 'already', 'under', 'when', 'than', 'after', 'amoungst', 'four', 'herein', 'its', 'say', 'never', 'ltd', 'perhaps', 'made', 'the', 'an', 'one', 'until', 'sincere', 'computer', 'not', 'who', 'hers', 'third', 'often', 'them', 'every', 'per', 'again', 'our', 'how', 'myself', 'had', 'from', 'two', 'off', 'of', 'hence', 'toward', 'amount', 'detail', 'quite', 'same', 'former', 'your', 'fill', 'five', 'over', 'system', 'we', 'find', 'she', 'just', 'yet', 'top', 'amongst', 'itself', 'nine', 'can', 'someone', 'others', 'something', 'con', 'what', 'etc', 'last', 'due', 'inc', 'put', 'forty', 'us', 'down', 'in', 'don', 'each', 'throughout', 'my', 'rather', 'enough', 'please', 'own', 'more', 'mostly', 'twelve', 'became', 'twenty', 'de', 'sometime', 'everywhere', 'make', 'or', 'anything', 'whose', 'back', 'towards', 'for', 'first', 'hereby', 'me', 'this', 'up', 'might', 'ever', 'these', 'since', 'eight', 'doing', 'mill', 'would', 'also', 'take', 'hereupon', 'sometimes', 'has', 'where', 'here', 'thereupon', 'and', 'as', 'whither', 'many', 'which', 'ourselves', 'at', 'empty', 'latterly', 'indeed', 'becomes', 'get', 'anyhow', 'front', 'go', 'kg', 'with', 'namely', 'do', 'against', 'while', 'into', 'ie', 'nowhere', 'whereas', 'are', 'thence', 'ten', 'anyone', 'didn', 'wherever', 'to', 'around', 'within', 'but', 'mine', 'therein', 'alone', 'you', 'yourself', 'moreover', 'nevertheless'})\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "all_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
        "print(all_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5d3414",
      "metadata": {
        "id": "be5d3414"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Adding Stop Words to Default Gensim Stop Words List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "db0749d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db0749d6",
        "outputId": "65287211-ca2f-43bd-e073-413c9824a6d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hence, to add an element, you have to apply the union function on the frozen set \\nand pass it the set of new stop words'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''A frozen set in Python is a type of set which is immutable. \n",
        "You cannot add or remove elements in a frozen set. '''\n",
        "'''Hence, to add an element, you have to apply the union function on the frozen set \n",
        "and pass it the set of new stop words'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a271dc27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a271dc27",
        "outputId": "f164014f-c128-4e64-e941-8dfe5a7f49af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'football', ',', 'fond', 'tennis', '.']\n"
          ]
        }
      ],
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "all_stopwords_gensim = STOPWORDS.union(set(['likes', 'play']))\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25253c5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''From the output above, you can see that the words like and play have been treated as stop words and \n",
        "consequently have been removed from the input sentence'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e8df331",
      "metadata": {
        "id": "1e8df331"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Removing Stop Words from Default Gensim Stopword List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa561ae9",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''You need to pass a set of stop words that you want to remove from the frozen set to the difference() method.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4eee783a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'not', 'fond', 'tennis', '.']\n"
          ]
        }
      ],
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "all_stopwords_gensim = STOPWORDS\n",
        "sw_list = {\"not\"}\n",
        "all_stopwords_gensim = STOPWORDS.difference(sw_list)\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be881aad",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Since the word not has now been removed from the stop word set, \n",
        "you can see that it has not been removed from the input sentence after stop word removal.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a40d82b",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Using the SpaCy Library</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e171ca37",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'fond', 'tennis', '.']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0fd5b9",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Adding and Removing Stop Words in SpaCy Default Stop Word List</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d886fc45",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "326\n",
            "{'except', 'together', 'above', 'regarding', '‘re', 'name', 'becoming', 'fifty', 'seems', 'between', 'himself', 'next', 'unless', 'other', 'herself', 'did', 'elsewhere', 'through', '’ve', 'nothing', 'neither', 'because', '‘s', 'whereafter', 'before', 'thereafter', 'least', 'whatever', 'side', 'should', 'behind', 'themselves', 'then', \"'d\", 'else', 'nor', 'seeming', 're', 'move', 'though', 'keep', 'thereby', 'somehow', 'below', 'any', 'beyond', 'always', 'could', 'further', 'yourselves', 'done', 'whenever', 'all', 'very', 'that', 'along', 'anyway', 'otherwise', 'really', 'serious', 'almost', 'will', 'by', 'three', 'yours', 'him', 'so', 'why', 'seemed', 'upon', 'fifteen', 'anywhere', 'however', 'beside', 'meanwhile', 'it', 'during', 'therefore', 'without', 'her', 'sixty', 'i', 'whole', 'cannot', 'show', 'eleven', 'afterwards', 'everything', 'less', 'full', 'still', 'such', 'on', 'onto', 'were', 'various', 'whether', '’m', 'a', 'only', 'his', 'been', 'their', 'none', \"'re\", 'via', 'must', 'among', 'whereupon', 'whom', 'whoever', 'another', 'if', 'was', 'well', 'latter', 'besides', 'am', 'is', 'even', 'whereby', 'have', 'they', 'although', 'about', 'somewhere', 'call', 'across', 'much', 'six', 'being', 'part', 'whence', 'those', 'some', 'noone', 'no', 'bottom', 'everyone', 'thru', 'once', 'out', 'hereafter', 'seem', 'too', 'either', '’ll', 'wherein', 'few', 'most', 'he', 'become', 'nobody', 'thus', 'using', 'may', 'give', 'several', 'does', 'hundred', 'be', 'now', '‘d', 'both', 'see', 'ours', '’d', 'formerly', 'there', 'used', 'beforehand', 'already', 'under', 'when', 'than', 'after', 'four', 'herein', 'its', 'say', 'never', 'perhaps', \"'m\", 'made', 'the', 'an', 'one', 'until', 'not', 'who', 'hers', 'third', 'often', 'n‘t', 'every', 'again', 'per', 'them', 'our', 'how', 'myself', 'had', 'from', 'two', 'off', 'of', 'hence', 'toward', 'amount', 'quite', 'same', 'former', 'your', 'five', 'over', \"'ve\", 'we', 'she', 'just', 'top', 'yet', 'amongst', 'itself', 'ca', 'nine', 'n’t', '‘ve', 'can', 'someone', 'others', 'something', 'what', 'last', 'due', '‘m', 'put', 'forty', 'us', 'down', 'in', 'each', 'throughout', 'my', 'rather', 'enough', 'please', 'more', 'own', '’re', 'mostly', 'became', 'twelve', 'twenty', 'sometime', 'everywhere', \"'ll\", 'make', 'or', 'anything', 'whose', 'back', 'towards', 'for', 'first', 'hereby', 'me', 'this', 'up', 'might', 'ever', 'these', 'since', '‘ll', 'eight', 'doing', '’s', 'take', 'also', 'would', 'hereupon', 'sometimes', 'has', 'where', \"'s\", 'here', 'thereupon', 'and', 'as', 'whither', 'many', 'which', 'ourselves', 'at', 'empty', 'latterly', 'becomes', 'indeed', 'anyhow', 'get', 'front', 'go', 'with', 'namely', \"n't\", 'do', 'against', 'while', 'into', 'nowhere', 'whereas', 'are', 'thence', 'ten', 'anyone', 'wherever', 'to', 'around', 'within', 'but', 'mine', 'alone', 'therein', 'you', 'yourself', 'moreover', 'nevertheless'}\n"
          ]
        }
      ],
      "source": [
        "print(len(all_stopwords))\n",
        "print(all_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b07d99",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Adding Stop Words to Default SpaCy Stop Words List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "61b3277e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'fond', '.']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords.add(\"tennis\")\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d089254d",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''The output shows that the word tennis has been removed from the input sentence.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adde1021",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''You can also add multiple words to the list of stop words in SpaCy as shown below. \n",
        "The following script adds likes and tennis to the list of stop words in SpaCy:'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3c6423f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'play', 'football', ',', 'fond', '.']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords |= {\"likes\",\"tennis\",}\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca90b8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''The ouput shows tha the words likes and tennis both have been removed from the input sentence.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4787573e",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Removing Stop Words from Default SpaCy Stop Words List</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "94b41e33",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nick', 'play', 'football', ',', 'not', 'fond', '.']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords.remove('not')\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d84ea3bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''In the output, you can see that the word not has not been removed from the input sentence.'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
