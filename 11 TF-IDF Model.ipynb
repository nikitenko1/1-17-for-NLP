{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50a97490",
      "metadata": {
        "id": "50a97490"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 28px; color: magenta\"> Python for NLP: Creating TF-IDF Model from Scratch</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23fb694d",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''TF-IDF model is one of the most widely used models for text to numeric conversion.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0277c210",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0277c210",
        "outputId": "bf1ca56f-0a03-405c-efcc-23197ee57d02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n Suppose we have a corpus with three sentences:\\n\\n\"I like to play football\"\\n\"Did you go outside to play tennis\"\\n\"John and I play tennis\"\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        " Suppose we have a corpus with three sentences:\n",
        "\n",
        "\"I like to play football\"\n",
        "\"Did you go outside to play tennis\"\n",
        "\"John and I play tennis\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24af06b2",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _1: Tokenize the Sentences</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61ca828f",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "The first step in this regard is to convert the sentences in our corpus into tokens or individual words\n",
        "Sentence 1\tSentence 2\tSentence 3\n",
        "I\t        Did\t        John\n",
        "like\t    you         and\n",
        "to\t        go\t        I\n",
        "play\t    outside\t    play\n",
        "football\tto\t    tennis\n",
        "            play\t\n",
        "            tennis\n",
        "'''\n",
        "\n",
        "'''The idea behind the TF-IDF approach is that the words that are more common in one sentence and\n",
        " less common in other sentences should be given high weights.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4173f260",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _2:  Find TF-IDF Values</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5921839b",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)\n",
        "'''\n",
        "\n",
        "'''For instance, look at the word \"play\" in the first sentence. Its term frequency will be 0.20 since the word \"play\" \n",
        "occurs only once in the sentence and \n",
        "the total number of words in the sentence are 5, hence, 1/5 = 0.20'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0d34fe7",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _3: Creating the Bag of Words Model</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbbe8dc",
      "metadata": {},
      "outputs": [],
      "source": [
        " \n",
        "'''IDF: (Total number of sentences (documents))/(Number of sentences (documents) containing the word)'''\n",
        "\n",
        "'''Let's find the IDF frequency of the word \"play\". Since we have three documents and the word \"play\" occurs \n",
        "in all three of them, \n",
        "therefore the IDF value of the word \"play\" is 3/3 = 1.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a4ca6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Finally, the TF-IDF values are calculated by multiplying TF values with their corresponding IDF values.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a5ffba",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Finally, we will filter the 8 most frequently occurring words.\n",
        "\n",
        "As I said earlier, since IDF values are calculated using the whole corpus, we can calculate the IDF value for each word now. \n",
        "The following table contains IDF values for each table.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcb6c25b",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Word     Frequency       IDF\n",
        "play        3               3/3 = 1\n",
        "\n",
        "tennis      2               3/2 = 1.5\n",
        "\n",
        "to          2               3/2 = 1.5\n",
        "  \t\n",
        "I           2               3/2 = 1.5\n",
        "...  \t\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4dd160",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Let's now find the TF-IDF values for all the words in each sentence.'''\n",
        "'''\n",
        "Word        Sentence 1          Sentence 2              Sentence 3\n",
        "play        0.20 x 1 = 0.20     0.14 x 1 = 0.14         0.20 x 1 = 0.20\n",
        "\n",
        "tennis      0 x 1.5 = 0         0.14 x 1.5 = 0.21       0.20 x 1.5 = 0.30\n",
        "  ...\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3fdbe61",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Note the use of the log function with TF-IDF.'''\n",
        "'''IDF: log((Total number of sentences (documents))/(Number of sentences (documents) containing the word))'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c157e1",
      "metadata": {},
      "source": [
        "<p style=\"font-family:Roboto; font-size: 28px; color: magenta\"> TF-IDF Model from Scratch in Python</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8cc7ed5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "raw_html = urllib.request.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text\n",
        "\n",
        "corpus = nltk.sent_tokenize(article_text)\n",
        "\n",
        "for i in range(len(corpus )):\n",
        "    corpus [i] = corpus [i].lower()\n",
        "    corpus [i] = re.sub(r'\\W',' ',corpus [i])\n",
        "    corpus [i] = re.sub(r'\\s+',' ',corpus [i])\n",
        "\n",
        "wordfreq = {}\n",
        "for sentence in corpus:\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    for token in tokens:\n",
        "        if token not in wordfreq.keys():\n",
        "            wordfreq[token] = 1\n",
        "        else:\n",
        "            wordfreq[token] += 1\n",
        "\n",
        "import heapq\n",
        "most_freq = heapq.nlargest(200, wordfreq, key=wordfreq.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1992b4f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "'''Finally, we create a dictionary of word frequencies and then filter the top 200 most frequently occurring words'''\n",
        "print(len(most_freq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c97806ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''The next step is to find the IDF values for the most frequently occurring words in the corpus.'''\n",
        "word_idf_values = {}\n",
        "for token in most_freq:\n",
        "    doc_containing_word = 0\n",
        "    for document in corpus:\n",
        "        if token in nltk.word_tokenize(document):\n",
        "            doc_containing_word += 1\n",
        "    word_idf_values[token] = np.log(len(corpus)/(1 + doc_containing_word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f9ab4c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "word_tf_values = {}\n",
        "for token in most_freq:\n",
        "    sent_tf_vector = []\n",
        "    for document in corpus:\n",
        "        doc_freq = 0\n",
        "        '''The next step is to create the TF dictionary for each word'''\n",
        "        for word in nltk.word_tokenize(document):\n",
        "            if token == word:\n",
        "                  doc_freq += 1\n",
        "        word_tf = doc_freq/len(nltk.word_tokenize(document))\n",
        "        sent_tf_vector.append(word_tf)\n",
        "    ''' In the script above word_tf_values is our dictionary. For each word, we create a list sent_tf_vector'''\n",
        "    word_tf_values[token] = sent_tf_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f85a61fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Now we have IDF values of all the words, along with TF values of every word across the sentences. \n",
        "The next step is to simply multiply IDF values with TF values'''\n",
        "tfidf_values = []\n",
        "for token in word_tf_values.keys():\n",
        "    tfidf_sentences = []\n",
        "    for tf_sentence in word_tf_values[token]:\n",
        "        tf_idf_score = tf_sentence * word_idf_values[token]\n",
        "        tfidf_sentences.append(tf_idf_score)\n",
        "    tfidf_values.append(tfidf_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "45a8067c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.00678011, 0.        , ..., 0.00794909, 0.01002277,\n",
              "        0.00390718],\n",
              "       [0.00894022, 0.00368127, 0.        , ..., 0.00647396, 0.01088375,\n",
              "        0.00212141],\n",
              "       [0.04542777, 0.0374111 , 0.03533271, ..., 0.01096532, 0.        ,\n",
              "        0.04311788],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''Now at this point in time, the tfidf_values is a list of lists.\\\n",
        "We need to convert the two-dimensional list to a numpy array'''\n",
        "tf_idf_model = np.asarray(tfidf_values)\n",
        "tf_idf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "99bc1f54",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.00894022, 0.04542777, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.00678011, 0.00368127, 0.0374111 , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.03533271, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.00794909, 0.00647396, 0.01096532, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.01002277, 0.01088375, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.00390718, 0.00212141, 0.04311788, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''We want rows to represent the TF-IDF vectors. We can do so by simply transposing our numpy array as follows'''\n",
        "tf_idf_model = np.transpose(tf_idf_model)\n",
        "tf_idf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264eee82",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
