{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50a97490",
      "metadata": {
        "id": "50a97490"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 28px; color: magenta\"> Python for NLP: Creating a Rule-Based Chatbot</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0277c210",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0277c210",
        "outputId": "bf1ca56f-0a03-405c-efcc-23197ee57d02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n A chatbot is a conversational agent capable of answering user queries in the form of text,\\n   speech, or via a graphical user interface\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        " A chatbot is a conversational agent capable of answering user queries in the form of text,\n",
        "   speech, or via a graphical user interface\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "212b0d2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "212b0d2d",
        "outputId": "6533ff9f-64d8-4253-ccdc-4e4ccd75c9cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nChatbots can be broadly categorized into two types: Task-Oriented Chatbots and General Purpose Chatbots\\nThe task-oriented chatbots are designed to perform specific tasks.\\nFor instance, a task-oriented chatbot can answer queries related to train reservation, pizza delivery;\\nit can also work as a personal medical therapist or personal assistant.\\n\\nOn the other hand, general purpose chatbots can have open-ended discussions with the users.\\n\\nThere is also a third type of chatbots called hybrid chatbots\\nthat can engage in both task-oriented and open-ended discussion with the users.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "'''\n",
        "Chatbots can be broadly categorized into two types: Task-Oriented Chatbots and General Purpose Chatbots\n",
        "The task-oriented chatbots are designed to perform specific tasks.\n",
        "For instance, a task-oriented chatbot can answer queries related to train reservation, pizza delivery;\n",
        "it can also work as a personal medical therapist or personal assistant.\n",
        "\n",
        "On the other hand, general purpose chatbots can have open-ended discussions with the users.\n",
        "\n",
        "There is also a third type of chatbots called hybrid chatbots\n",
        "that can engage in both task-oriented and open-ended discussion with the users.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a43d3321",
      "metadata": {
        "id": "a43d3321"
      },
      "source": [
        "<p style=\"font-family:consolas; font-size: 26px; color: magenta; text-decoration-line: overline; \"> Chatbot development approaches fall in two categories: rule-based chatbots and learning-based chatbots.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0170c96b",
      "metadata": {
        "id": "0170c96b"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Learning-Based Chatbots</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836e771f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "836e771f",
        "outputId": "ba9aad7a-6585-47f3-ed3c-15234fee1752"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLearning-based chatbots are the type of chatbots that use machine learning techniques and a dataset \\nto learn to generate a response to user queries. \\nLearning-based chatbots can be further divided into two categories: retrieval-based chatbots and generative chatbots.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "Learning-based chatbots are the type of chatbots that use machine learning techniques and a dataset\n",
        "to learn to generate a response to user queries.\n",
        "Learning-based chatbots can be further divided into two categories: retrieval-based chatbots and generative chatbots.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10381dba",
      "metadata": {
        "id": "10381dba"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Rule-Based Chatbots</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57da2f57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "57da2f57",
        "outputId": "b24485eb-4767-4ea7-8bce-e2e0e142e42a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nThere are a specific set of rules. If the user query matches any rule, the answer to the query is generated, \\notherwise the user is notified that the answer to user query doesn't exist.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''\n",
        "There are a specific set of rules. If the user query matches any rule, the answer to the query is generated,\n",
        "otherwise the user is notified that the answer to user query doesn't exist.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2ff5ea39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2ff5ea39",
        "outputId": "8193a952-fd65-4afc-a74e-e9fe9d96db22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWhen a user enters a query, the query will be converted into vectorized form.\\nAll the sentences in the corpus will also be converted into their corresponding vectorized forms.\\nNext, the sentence with the highest cosine similarity\\nwith the user input vector will be selected as a response to the user input.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "When a user enters a query, the query will be converted into vectorized form.\n",
        "All the sentences in the corpus will also be converted into their corresponding vectorized forms.\n",
        "Next, the sentence with the highest cosine similarity\n",
        "with the user input vector will be selected as a response to the user input.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62b8a92c",
      "metadata": {
        "id": "62b8a92c"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf908ff",
      "metadata": {
        "id": "4bf908ff"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Creating the Corpus</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "278386ce",
      "metadata": {
        "id": "278386ce"
      },
      "outputs": [],
      "source": [
        "# The following script retrieves the Wikipedia article\n",
        "raw_html = urllib.request.urlopen('https://en.wikipedia.org/wiki/Tennis')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "# extracts all the paragraphs from the article text\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text\n",
        "# text is converted into the lower case for easier processing\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5582b6e",
      "metadata": {
        "id": "a5582b6e"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Text Preprocessing and Helper Function</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "96793907",
      "metadata": {
        "id": "96793907"
      },
      "outputs": [],
      "source": [
        "# remove all the special characters\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "# remove all the empty spaces\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "514c53b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "514c53b7",
        "outputId": "0403e861-d47f-4cd8-f393-7ec95aebf713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "#  divide our text into sentences and word\n",
        "nltk.download('punkt_tab')\n",
        "article_sentences = nltk.sent_tokenize(article_text)\n",
        "article_words = nltk.word_tokenize(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "96104d23",
      "metadata": {
        "id": "96104d23"
      },
      "outputs": [],
      "source": [
        "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def perform_lemmatization(tokens):\n",
        "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
        "# The punctuation_removal list removes the punctuation from the passed text\n",
        "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
        "\n",
        "def get_processed_text(document):\n",
        "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24da85ac",
      "metadata": {
        "id": "24da85ac"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Responding to Greetings</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bbc748ec",
      "metadata": {
        "id": "bbc748ec"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "When a user enters a greeting, we will try to search it in the greetings_inputs list, if the greeting is found,\n",
        "we will randomly choose a response from the greeting_outputs list\n",
        "'''\n",
        "greeting_inputs = (\"hey\", \"good morning\", \"good evening\", \"morning\", \"evening\", \"hi\", \"whatsup\")\n",
        "greeting_responses = [\"hey\", \"hey hows you?\", \"*nods*\", \"hello, how you doing\", \"hello\", \"Welcome, I am good and you\"]\n",
        "\n",
        "def generate_greeting_response(greeting):\n",
        "    for token in greeting.split():\n",
        "        if token.lower() in greeting_inputs:\n",
        "            return random.choice(greeting_responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abcbad8f",
      "metadata": {
        "id": "abcbad8f"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Responding to User Queries</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7f5b56c5",
      "metadata": {
        "id": "7f5b56c5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "he response will be generated based upon the cosine similarity of the vectorized form\n",
        "of the input sentence and the sentences in the corpora\n",
        "'''\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "056a55f0",
      "metadata": {
        "id": "056a55f0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We will create a method that takes in user input, finds the cosine similarity of the user input\n",
        "and compares it with the sentences in the corpus\n",
        "'''\n",
        "def generate_response(user_input):\n",
        "    tennisrobo_response = ''\n",
        "    article_sentences.append(user_input)\n",
        "\n",
        "    word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
        "    all_word_vectors = word_vectorizer.fit_transform(article_sentences)\n",
        "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
        "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
        "\n",
        "    matched_vector = similar_vector_values.flatten()\n",
        "    matched_vector.sort()\n",
        "    vector_matched = matched_vector[-2]\n",
        "\n",
        "    if vector_matched == 0:\n",
        "        tennisrobo_response = tennisrobo_response + \"I am sorry, I could not understand you\"\n",
        "        return tennisrobo_response\n",
        "    else:\n",
        "        tennisrobo_response = tennisrobo_response + article_sentences[similar_sentence_number]\n",
        "        return tennisrobo_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "03bec138",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03bec138",
        "outputId": "15252f8e-b81a-4d72-e034-82fad5a38b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
        "# We initialize the tfidfvectorizer and then convert all the sentences in the corpus along with the input sentence\n",
        "# into their corresponding vectorized form.\n",
        "nltk.download('wordnet')\n",
        "all_word_vectors = word_vectorizer.fit_transform(article_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "45c90e53",
      "metadata": {
        "id": "45c90e53"
      },
      "outputs": [],
      "source": [
        "similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fa6fa32c",
      "metadata": {
        "id": "fa6fa32c"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We use the cosine_similarity function to find the cosine similarity between the last item in the all_word_vectors list\n",
        "(which is actually the word vector for the user input since it was appended at the end)\n",
        "and the word vectors for all the sentences in the corpus.\n",
        "'''\n",
        "similar_sentence_number = similar_vector_values.argsort()[0][-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dac15218",
      "metadata": {
        "id": "dac15218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7a03b5e7-6fc5-4a1a-da46-195f10325c37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWe sort the list containing the cosine similarities of the vectors, the second last item in the list will actually\\nhave the highest cosine (after sorting) with the user input.\\nThe last item is the user input itself, therefore we did not select that.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "'''\n",
        "We sort the list containing the cosine similarities of the vectors, the second last item in the list will actually\n",
        "have the highest cosine (after sorting) with the user input.\n",
        "The last item is the user input itself, therefore we did not select that.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a6f241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "a3a6f241",
        "outputId": "d9a46e78-4a05-458f-fe59-b524a07dd919"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIf the cosine similarity of the matched vector is 0, that means our query did not have an answer. \\nIn that case, we will simply print that we do not understand the user query.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "'''\n",
        "If the cosine similarity of the matched vector is 0, that means our query did not have an answer.\n",
        "In that case, we will simply print that we do not understand the user query.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f696764f",
      "metadata": {
        "id": "f696764f"
      },
      "source": [
        "<p style=\"font-family:Roboto; font-size: 22px; color: orange; text-decoration-line: overline; \"> Part: _Chatting with the Chatbot</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4bbe0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd4bbe0a",
        "outputId": "539256cb-b1e4-4fb3-d61b-aa5a9856dfba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am your friend TennisRobo. You can ask me any question regarding tennis:\n",
            "Novak Djokovic\n",
            "TennisRobo: by the early twenty-first century, the 'big three' of roger federer, rafael nadal and novak djokovic have dominated men's singles tennis for two decades, collectively winning 66 major singles tournaments; djokovic with an all-time record 24 titles, nadal with 22 and federer with 20. they have been ranked as world no.\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "As a final step, we need to create a function that allows us to chat with the chatbot that we just designed.\n",
        "To do so, we will write another helper function\n",
        "that will keep executing until the user types \"Bye\".\n",
        "'''\n",
        "continue_dialogue = True\n",
        "print(\"Hello, I am your friend TennisRobo. You can ask me any question regarding tennis:\")\n",
        "# we first set the flag continue_dialogue to true\n",
        "while(continue_dialogue == True):\n",
        "    human_text = input()\n",
        "    human_text = human_text.lower()\n",
        "    if human_text != 'bye':\n",
        "        if human_text == 'thanks' or human_text == 'thank you very much' or human_text == 'thank you':\n",
        "            continue_dialogue = False\n",
        "            print(\"TennisRobo: Most welcome\")\n",
        "        else:\n",
        "            if generate_greeting_response(human_text) != None:\n",
        "                # After that, we print a welcome message to the user asking for any input\n",
        "                # if the user input is not equal to None, the generate_response method is called which fetches the user response\n",
        "                # based on the cosine similarity as explained in the last section\n",
        "                print(\"TennisRobo: \" + generate_greeting_response(human_text))\n",
        "            else:\n",
        "                print(\"TennisRobo: \", end=\"\")\n",
        "                print(generate_response(human_text))\n",
        "                article_sentences.remove(human_text)\n",
        "    else:\n",
        "        continue_dialogue = False\n",
        "        print(\"TennisRobo: Good bye and take care of yourself...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kDfJLP5NuNL"
      },
      "id": "5kDfJLP5NuNL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}